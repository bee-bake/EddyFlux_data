---
title: "FCR_Process_BD"
author: "Brenda D'Achuna, Alex Hounshell, Adrienne Breef-Pilz"
date: "`r sys.Date()`"
output: html_document
---

 This script: Following initial data corrections in Eddy Pro (using standard processing) 
 and light data cleaning via EddyPro_CleanUp.R
 
 Original code from Brenda D'Achuna, 21 May 2021
 Modified by Alex Hounshell on 21 May 2021
 
 1. Compile data
 
 2. Read in Met files from Environmental Data Initiative
 
 3. Adjust values and do additional QAQC
 
 4. Use de spike function to remove values
 
 5. Add Met values as needed
 
 6. Gaps fill. Beware this takes HOURS!!!!!
 
 7. Save files
 
 8. Plots for checks
 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# Download/load libraries
pacman::p_load(tidyverse,lubridate,readr,ggpubr,openair,REddyProc)

# functions we need
source("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataNotYetUploadedToEDI/EddyFlux_Processing/despike.R")
```


```{r Compile data, include=FALSE}
# Read compiled file: From Eddy Pro using basic processing
# Original file from Brenda on 11 May 2021
# Light data cleaning using EddyPro_CleanUp.R

dt1 <-read_csv("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataNotYetUploadedToEDI/EddyFlux_Processing/EddyPro_Cleaned_L1.csv")

# Check here on EDI an make sure you are using the most up to date file.
# https://portal.edirepository.org/nis/mapbrowse?packageid=edi.1061.2 
# if not pulll in the file path from EDI


# read in the data file downloaded from EDI
dt2 <-read_csv("https://pasta.lternet.edu/package/data/eml/edi/1061/2/f837d12dc12ab37a6772598578875e00") 

ec <- dt2%>%
  bind_rows(.,dt1)
```

```{r format time, echo=FALSE}
# Format time
# make a datetime column and read in with original timezone
ec$datetime <- paste0(ec$date, " ",ec$time)

# Set timezone as America/New_York because that's what it is in and then conver to EST
  ec$datetime <- force_tz(ymd_hms(ec$datetime), tzone = "America/New_York")

# convert from Eastern/US with daylight savings observed to EST which does not. 
ec$datetime <- with_tz(as.POSIXct(ec$datetime, "%Y-%m-%d %H:%M:%S", tzone = "EST"))


# get the late date in the dataframe
last <- tail(ec, n=1) 

# Set new dataframe with list of dates+times:
# every 30 minutes
# Constrain to study time period: 2020-04-05 (time series start date) to
# last 30 minute period - UPDATE WITH EACH NEW SET OF DATA!
ts <- seq.POSIXt(as.POSIXct("2020-04-05 00:00:00","%Y-%m-%d %H:%M:%S", tz="EST"), 
                 as.POSIXct("2024-05-06 11:30:00", "%Y-%m-%d %H:%M:%S", tz="EST"), by = "30 min") #last$datetime not used here due to daylight issues 
ts2 <- data.frame(datetime = ts)

# Join Eddy Flux data with list of dates+time
ec2 <- merge(ts2, ec, by = 'datetime', all.x = TRUE) %>%
  distinct(datetime, .keep_all = TRUE) #remove duplicated rows

# Make sure time stamps are okay!
ec2 %>% group_by(year = year(datetime), month = factor(month.abb[month(datetime)], levels = c("Apr", "May", "Jun",
                                                                                                 "Jul", "Aug", "Sep", "Oct", 'Nov', 
                                                                                                 'Dec', 'Jan', 'Feb', 'Mar')), 
                    hour = hour(datetime)) %>% 
  summarise(air_temperature = mean(air_temperature_k, na.rm = TRUE)) %>% 
  ggplot(aes(hour, air_temperature, col = factor(year))) + geom_point() + 
  facet_wrap(~month) + theme_bw() + ylab('Air Temp') + xlab("") +
  scale_color_brewer(palette = "Dark2")
```

```{r Percent of NAs, echo=FALSE}
#################################################################
# Count how many initial NAs are in CO2 and CH4 data
# Without any data processing!
#################################################################
sta<-ec2 %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# 70% data for CO2; 72% data for CH4

# Check data availability by month
ec2 %>% group_by(year(datetime), month(datetime)) %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
#################################################################
```

```{r Inital Flux plots, echo=FALSE}

ec2%>%
  select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s)%>%
  tidyr::pivot_longer(cols=c(co2_flux_umolm2s, ch4_flux_umolm2s), # make the wide data frame into a long one so each observation has a depth
                 names_to='variable',
                 values_to='observation')%>%
  ggplot(., aes(x=datetime, y=observation))+
  geom_point()+
  facet_wrap(~variable, scales="free_y", ncol=1)+
   ggtitle("Inital Fluxes Prime 0")+
  theme_bw()+
   theme(plot.title = element_text(hjust = 0.5))
  
ggsave("FCR_InitalFluxes.jpg", width=11, height=7, units="in")


```


Count how many initial NAs are in CO2 and CH4 data. Without any data processing!
`r round(sta$co2_available, digits=1)`% data for Co2;  
`r round(sta$ch4_available, digits=1)`% data for Ch4

```{r Read in Met Data, include=FALSE}
# Reading in data from the Met Station for gap-filling purposes
# Load data Meteorological data from EDI


# Read in Met file from EDI
met_all <- read_csv("https://pasta.lternet.edu/package/data/eml/edi/389/8/d4c74bbb3b86ea293e5c52136347fbb0",
                    col_select=c("DateTime","PAR_umolm2s_Average","PAR_Total_mmol_m2","BP_Average_kPa",
                                 "AirTemp_C_Average","RH_percent","Rain_Total_mm",
                                 "ShortwaveRadiationUp_Average_W_m2", "ShortwaveRadiationDown_Average_W_m2",
                                  "InfraredRadiationUp_Average_W_m2","InfraredRadiationDown_Average_W_m2",
                                  "Albedo_Average_W_m2","WindSpeed_Average_m_s","WindDir_degrees"))%>%
  mutate(DateTime = force_tz(DateTime, tzone="EST"))%>% 
  # Start timeseries on the 00:15:00 to facilitate 30-min averages
  filter(DateTime >= ymd_hms("2020-04-04 00:15:00"))

# Bind files together if need to use current file

met_curr <- read_csv("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-metstation-data-qaqc/FCRmet_L1.csv",
                   col_select=c("DateTime","PAR_umolm2s_Average","PAR_Total_mmol_m2","BP_Average_kPa",
                                 "AirTemp_C_Average","RH_percent","Rain_Total_mm",
                                 "ShortwaveRadiationUp_Average_W_m2", "ShortwaveRadiationDown_Average_W_m2",
                                  "InfraredRadiationUp_Average_W_m2","InfraredRadiationDown_Average_W_m2",
                                  "Albedo_Average_W_m2","WindSpeed_Average_m_s","WindDir_degrees"))%>%
  mutate(DateTime = force_tz(DateTime, tzone="EST"))

 met_all <- dplyr::bind_rows(met_curr, met_all) # bind everything together
  
  
# Start timeseries on the 00:15:00 to facilitate 30-min averages

# Select data every 30 minutes from Jan 2020 to end of met data
met_all$Breaks <- cut(met_all$DateTime,breaks = "30 mins",right=FALSE)
met_all$Breaks <- ymd_hms(as.character(met_all$Breaks))

# Average met data to the 30 min mark (excluding Total Rain and Total PAR)
met_30 <- met_all %>% 
 select(-c(Rain_Total_mm,PAR_Total_mmol_m2))%>%
  group_by(Breaks) %>% 
  summarise_all(mean,na.rm=TRUE)
```

```{r Adjust Met values for EddyFlux timing, include=FALSE}
# Sum met data to the 30 min mark (for Total Rain and Total PAR)
met_30_rain <- met_all %>% 
  select(Rain_Total_mm,PAR_Total_mmol_m2,Breaks) %>% 
  group_by(Breaks) %>% 
  summarise_all(sum,na.rm=TRUE)

# Combine averaged and summed data together
met_30_2 <- cbind.data.frame(met_30,met_30_rain)

# Adjust datetime to 30 minute intervals, select relevant parameters, and rename
# following Brenda's conventions
met_30_2 <- met_30_2 %>% 
  select(-Breaks) %>% 
  mutate(DateTime_Adj = DateTime + 30) %>% 
  select(-DateTime) %>% 
  rename(datetime = DateTime_Adj, AirTC_Avg = AirTemp_C_Average, RH = RH_percent, Pressure = BP_Average_kPa, 
         Rain_sum = Rain_Total_mm, WS_ms_Avg = WindSpeed_Average_m_s, WindDir = WindDir_degrees,SW_in = ShortwaveRadiationUp_Average_W_m2,
         SW_out = ShortwaveRadiationDown_Average_W_m2,LW_in = InfraredRadiationUp_Average_W_m2,LW_out = InfraredRadiationDown_Average_W_m2,
         PAR_Tot_Tot = PAR_Total_mmol_m2,albedo = Albedo_Average_W_m2)

# Join with 30 minute time series
met2 <- merge(ts2, met_30_2, by = 'datetime', all.x = TRUE)
```

```{r Compare wind speeds from EC and Met}
# Compare wind speeds from EC and Met
ggplot()+
  geom_point(aes(x=ec2$wind_speed_ms, y=met2$WS_ms_Avg))+
  theme_classic(base_size = 15)
  

# Calculate percent of missing wind data
# 14% missing
miss_ws<-ec2 %>% select(datetime, wind_speed_ms) %>% 
  summarise(wnd_na = sum(is.na(wind_speed_ms))/n()*100)
```

We are missing `r round(miss_ws$wnd_na, digits=1)` % of the windspeed observations

```{r Use linear model to convert from Met to EC for missing time point}
# Use linear model to convert from Met to EC for missing time point
linearMod <- lm(ec2$wind_speed_ms ~ met2$WS_ms_Avg)
summary(linearMod)
cor(ec2[[49]],met2[[11]],use = "complete.obs",method=c("pearson"))

# UPDATE EVERY YEAR WITH NEW RELATIONSHIP
# For data period: EC = Met*0.500243+0.214460

# Check conversion - UPDATE EVERY YEAR WITH NEW RELATIONSHIP
plot(ec2$datetime, ec2$wind_speed_ms)
points(ec2$datetime, met2$WS_ms_Avg*(summary(linearMod)$coefficients[2, 1])+(summary(linearMod)$coefficients[1, 1]), col = 'red')
```

The new relationship between the wind speed on the Metstation and the EddyFlux is 

EC= Met* 
`r summary(linearMod)$coefficients[2, 1]` + 
`r summary(linearMod)$coefficients[1, 1]`

```{r QC when wind in wrong direction}
###########################################
# Use converted wind speed from the Met data to fill in time points with missing
# data (EC)
# UPDATE EVERY YEAR WITH NEW RELATIONSHIP
ec2$wind_speed_ms <- ifelse(is.na(ec2$wind_speed_ms),
                         met2$WS_ms_Avg*(summary(linearMod)$coefficients[2, 1])+
                           (summary(linearMod)$coefficients[1, 1]), ec2$wind_speed_ms)

ec2$wind_dir <- ifelse(is.na(ec2$wind_dir),
                       met2$WindDir, ec2$wind_dir)

# Visualize wind directions that are IN FRONT of the catwalk
ec2 %>% filter(wind_dir >= 250 | wind_dir <= 80) %>% 
  ggplot(aes(wind_dir, wind_speed_ms)) + 
  geom_point() +
  scale_x_continuous(limits = c(0, 360),
                     breaks = seq(0, 360, 45)) +
  coord_polar() + theme_bw() + xlab('Wind direction') + ylab('Wind speed')

# Filter out wind directions that are BEHIND the catwalk
# I.e., only keep data that is IN FRONT of the catwalk for both EC and Met data
ec_filt <- ec2 %>% dplyr::filter(wind_dir < 80 | wind_dir > 250)
ec_filt <- left_join(ts2, ec_filt)

met3 <- met2 %>% dplyr::filter(WindDir < 80 | WindDir > 250)
met4 <- left_join(ts2, met3)

################################################################
# count NA after filtering for wind direction BEHIND catwalk
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100- sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# Now have 59% CO2 data and 51% CH4 data

# Count number of timepoints that have data
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = n() - sum(is.na(co2_flux_umolm2s)),
            ch4_available = n() -sum(is.na(ch4_flux_umolm2s)))
################################################################
```

```{r QC on CO2 fluxes}
# Remove large CO2 values
# Visualize data that is above/below abs(100)
plot(ec_filt$datetime, ec_filt$co2_flux_umolm2s)+
abline(h=200, col="red") +
abline(h=-100, col="red")

# Remove values that are greater than abs(100)
# NOTE: Updated from Brenda's code to use abs(100); instead of -70 to 100 filtering
# Waldo et al. 2021 used: values greater than abs(15000)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$co2_flux_umolm2s > 100 | ec_filt$co2_flux_umolm2s < -100, NA, ec_filt$co2_flux_umolm2s)

# Remove CO2 data if QC >= 2 (aka: data that has been flagged by Eddy Pro)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$qc_co2_flux >= 2, NA, ec_filt$co2_flux_umolm2s)

# Additionally remove CO2 data when H and LE > 2 (following CH4 filtering)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$qc_co2_flux==1 & ec_filt$qc_LE>=2, NA, ec_filt$co2_flux_umolm2s)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$qc_co2_flux==1 & ec_filt$qc_H>=2, NA, ec_filt$co2_flux_umolm2s)
```

```{r QC on Ch4 fluxes}
# Remove large CH4 values
# Visualize data that is above/below abs(0.25)
plot(ec_filt$datetime, ec_filt$ch4_flux_umolm2s)+
abline(h=0.25, col='red')+
abline(h=-0.25, col='red')

# Remove values that are greater than abs(0.25)
# NOTE: Updated from Brenda's code to use abs(0.25)
# Waldo et al. 2021 used: values greater than abs(500)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$ch4_flux_umolm2s >= 0.25 | ec_filt$ch4_flux_umolm2s <= -0.25, NA, ec_filt$ch4_flux_umolm2s)

# Remove ch4 values when signal strength < 20
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$rssi_77_mean < 20, NA, ec_filt$ch4_flux_umolm2s)

# Remove CH4 data if QC >= 2
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux >=2, NA, ec_filt$ch4_flux_umolm2s)

# Additionally, remove CH4 when other parameters are QA/QC'd 
# Following Waldo et al. 2021: Remove additional ch4 flux data 
# (aka: anytime ch4_qc flag = 1 & another qc_flag =2, remove)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux==1 & ec_filt$qc_co2_flux>=2, NA, ec_filt$ch4_flux_umolm2s)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux==1 & ec_filt$qc_LE>=2, NA, ec_filt$ch4_flux_umolm2s)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux==1 & ec_filt$qc_H>=2, NA, ec_filt$ch4_flux_umolm2s)
```

```{r Check QC for H and LE}
# Removing qc >= 2 for H and LE
ec_filt$H_wm2 <- ifelse(ec_filt$qc_H >= 2, NA, ec_filt$H_wm2)
ec_filt$LE_wm2 <- ifelse(ec_filt$qc_LE >= 2, NA, ec_filt$LE_wm2)

# Remove high H values: greater than abs(200)
# NOTE: Updated to have same upper and lower magnitude bound
# Waldo et al. 2021 used abs of 200 for H
plot(ec_filt$datetime, ec_filt$H_wm2)+
abline(h=200, col='red')+
abline(h=-200, col='red')

ec_filt$H_wm2 <- ifelse(ec_filt$H_wm2 >= 200 | ec_filt$H_wm2 <= -200, NA, ec_filt$H_wm2)

# Remove high LE values: greater than abs(500)
# NOTE: Updated to have same upper and lower magnitude bounds
# Waldo et al. 2021 used abs of 1000 for LE
plot(ec_filt$datetime,ec_filt$LE_wm2)+
abline(h=500, col='red')+
abline(h=-500, col='red')

ec_filt$LE_wm2 <- ifelse(ec_filt$LE_wm2 >= 500 | ec_filt$LE_wm2 <= -500, NA, ec_filt$LE_wm2)

# Plotting co2 and ch4 to see if we can filter implausible values
plot(ec_filt$co2_flux_umolm2s, type = 'o')
plot(ec_filt$ch4_flux_umolm2s, type = 'o')
```

```{r Take out CH4 flux when rain}
################################################################
# count NA after filtering for bad fluxes
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100- sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# Now have 39% CO2 data and 33% CH4 data

# Count number of timepoints that have data
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = n() - sum(is.na(co2_flux_umolm2s)),
            ch4_available = n() -sum(is.na(ch4_flux_umolm2s)))
################################################################

# Remove CH4 when it rains
ec_filt$precip <- met2$Rain_sum
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$precip > 0, NA, ec_filt$ch4_flux_umolm2s)

# Remove CH4 data when thermocouple was not working (apr 05 - apr 25) # ABP find for 2023
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$datetime >= '2021-04-05' & ec_filt$datetime <= '2021-04-25', 
                           NA, ec_filt$ch4_flux_umolm2s)

# Merge with timeseries
eddy_fcr <- left_join(ts2, ec_filt, by = 'datetime')
```

```{r Count data}
#######################################################################
# counting data again after filtering by:
# wind direction, qc, rain, unreasonable values, signal strength
eddy_fcr %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# 39% CO2 data; 30% CH4 data

# Number of timepoints available
eddy_fcr %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = n() - sum(is.na(co2_flux_umolm2s)),
            ch4_available = n() -sum(is.na(ch4_flux_umolm2s)))

# Data availability by month
eddy_fcr %>% group_by(year(datetime), month(datetime)) %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
```

```{r Use Despike function}
########################################################################
# Despike data using dspike.R function

# Despike NEE (CO2 flux)


# Calculate low, medium, and high data flags
flag <- spike_flag(eddy_fcr$co2_flux_umolm2s,z = 7)
NEE_low <- ifelse(flag == 1, NA, eddy_fcr$co2_flux_umolm2s)
flag <- spike_flag(eddy_fcr$co2_flux_umolm2s,z = 5.5)
NEE_medium <- ifelse(flag == 1, NA, eddy_fcr$co2_flux_umolm2s)
flag <- spike_flag(eddy_fcr$co2_flux_umolm2s,z = 4)
NEE_high <- ifelse(flag == 1, NA, eddy_fcr$co2_flux_umolm2s)

# Plot flagged data:
plot(eddy_fcr$datetime,eddy_fcr$co2_flux_umolm2s,xlab = "Date", ylab = "NEE (umol m-2s-1)", col = "gray70")+
points(eddy_fcr$datetime,NEE_low,col = "gray10")+
points(eddy_fcr$datetime,NEE_medium,col = "blue")+
points(eddy_fcr$datetime,NEE_high,col = "red")+
abline(h=0)

# Combine all flagged data
eddy_fcr$NEE.low <- NEE_low
eddy_fcr$NEE.med <- NEE_medium
eddy_fcr$NEE.high <- NEE_high

#Despike CH4 flux
flag <- spike_flag(eddy_fcr$ch4_flux_umolm2s,z = 7)
CH4_low <- ifelse(flag == 1, NA, eddy_fcr$ch4_flux_umolm2s)
flag <- spike_flag(eddy_fcr$ch4_flux_umolm2s,z = 5.5)
CH4_medium <- ifelse(flag == 1, NA, eddy_fcr$ch4_flux_umolm2s)
flag <- spike_flag(eddy_fcr$ch4_flux_umolm2s,z = 4)
CH4_high <- ifelse(flag == 1, NA, eddy_fcr$ch4_flux_umolm2s)

# Plot flagged data:
plot(eddy_fcr$datetime,eddy_fcr$ch4_flux_umolm2s,xlab = "Date", ylab = "CH4 (umol m-2s-1)", col = "gray70")+
points(eddy_fcr$datetime,CH4_low,col = "gray10")+
points(eddy_fcr$datetime,CH4_medium,col = "blue")+
points(eddy_fcr$datetime,CH4_high,col = "red")+
abline(h=0)

# Combine all flagged data
eddy_fcr$ch4.low <- CH4_low
eddy_fcr$ch4.med <- CH4_medium
eddy_fcr$ch4.high <- CH4_high
```

```{r QAQC using Met data}
##########################################################################
# Convert EC temperature to celsius
eddy_fcr$air_temp_celsius <- eddy_fcr$air_temperature_k - 273.15
eddy_fcr$sonic_temp_celsius <- eddy_fcr$sonic_temperature_k - 273.15

# Plot temperature
ggplot(eddy_fcr,mapping=aes(x=datetime,y=air_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

ggplot(eddy_fcr,mapping=aes(x=datetime,y=sonic_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

# Remove any values over 40 

eddy_fcr$air_temp_celsius <- ifelse(eddy_fcr$air_temp_celsius>40, NA, 
                                    eddy_fcr$air_temp_celsius)

# Remove bad air temps on 10 Feb to 14 Feb
eddy_fcr$air_temp_celsius <- ifelse(eddy_fcr$datetime >= '2021-02-10' & eddy_fcr$datetime <='2021-02-14', NA, 
                                    eddy_fcr$air_temp_celsius)
eddy_fcr$sonic_temp_celsius <- ifelse(eddy_fcr$datetime >= '2021-02-10' & eddy_fcr$datetime <='2021-02-14', NA, 
                                      eddy_fcr$sonic_temp_celsius)

# Remove high temperatures on 11 November 2020
eddy_fcr$air_temp_celsius <- ifelse(eddy_fcr$datetime >= '2020-11-11' & eddy_fcr$datetime <'2020-11-12', NA, 
                                    eddy_fcr$air_temp_celsius)

eddy_fcr$sonic_temp_celsius <- ifelse(eddy_fcr$datetime >= '2020-11-11' & eddy_fcr$datetime <'2020-11-12', NA, 
                                    eddy_fcr$sonic_temp_celsius)
```

```{r Replacing Eddy Flux air temp with Met air temp}
# Replacing Eddy Flux air temp with Met air temp
# Check correlations between EC temp and Met Temp
ggplot()+
  geom_point(aes(x=eddy_fcr$air_temp_celsius,y=met2$AirTC_Avg))+
  theme_classic(base_size = 15)

# Calculate percent of missing air temp data
# 39% missing
eddy_fcr %>% select(datetime, air_temp_celsius) %>% 
  summarise(temp_na = sum(is.na(air_temp_celsius))/n()*100)

# Use linear model to estimate EC temp from Met temp
linearMod_Air <- lm(eddy_fcr$air_temp_celsius ~ met2$AirTC_Avg)
summary(linearMod_Air)
cor(eddy_fcr[[88]],met2[[4]],use = "complete.obs",method=c("pearson"))
# EC = Met*0.946533-0.961847
# UPDATE RELATIONSHIP EACH YEAR!!

eddy_fcr$air_temp_celsius <- ifelse(is.na(eddy_fcr$air_temp_celsius),
                                    met2$AirTC_Avg*(summary(linearMod_Air)$coefficients[2, 1])+
                           (summary(linearMod_Air)$coefficients[1, 1]), eddy_fcr$air_temp_celsius)

# Check Air Temp
ggplot(eddy_fcr,mapping=aes(x=datetime,y=air_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

# Check correlations between EC temp (sonic) and Met Temp
ggplot()+
  geom_point(aes(x=eddy_fcr$sonic_temp_celsius,y=met2$AirTC_Avg))+
  theme_classic(base_size = 15)

# Calculate percent of missing sonic temp data
# 39% missing
eddy_fcr %>% select(datetime, sonic_temp_celsius) %>% 
  summarise(temp_na = sum(is.na(sonic_temp_celsius))/n()*100)

# Use linear model to estimate EC temp and Met temp
linearMod_Air2 <- lm(eddy_fcr$sonic_temp_celsius ~ met2$AirTC_Avg)
summary(linearMod_Air2)
cor(eddy_fcr[[89]],met2[[4]],use = "complete.obs",method=c("pearson"))
# EC = Met*0.81-12.097
# UPDATE RELATIONSHIP EACH YEAR!!

eddy_fcr$sonic_temp_celsius <- ifelse(is.na(eddy_fcr$sonic_temp_celsius),
                                      eddy_fcr$air_temp_celsius*(summary(linearMod_Air2)$coefficients[2, 1])+
                           (summary(linearMod_Air2)$coefficients[1, 1]), eddy_fcr$sonic_temp_celsius)

# Check sonic temp
ggplot(eddy_fcr,mapping=aes(x=datetime,y=sonic_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

# Replacing Eddy Flux RH with Met RH
# Check correlations between EC and Met RH
ggplot()+
  geom_point(aes(x=eddy_fcr$RH,y=met2$RH))+
  theme_classic(base_size = 15)

# Calculate percent of missing sonic temp data
# 41% missing
eddy_fcr %>% select(datetime, RH) %>% 
  summarise(RH_na = sum(is.na(RH))/n()*100)

# Use linear model to estimate EC RH from Met RH
linearMod_RH <- lm(eddy_fcr$RH ~ met2$RH)
summary(linearMod_RH)
cor(eddy_fcr[[46]],met2[[5]],use = "complete.obs",method=c("pearson"))
# EC = Met*0.845661 + 7.712944
# UPDATE EACH YEAR!!

eddy_fcr$RH <- ifelse(is.na(eddy_fcr$RH),
                      met2$RH*(summary(linearMod_RH)$coefficients[2, 1])+
                           (summary(linearMod_RH)$coefficients[1, 1]), eddy_fcr$RH)

# Add Met data to gapfill fluxes
eddy_fcr$SW_in <- met2$SW_in
eddy_fcr$SW_out <- met2$SW_out
eddy_fcr$par_tot <- met2$PAR_Tot_Tot
eddy_fcr$air_pressure <- met2$Pressure
eddy_fcr$LW_in <- met2$LW_in
eddy_fcr$LW_out <- met2$LW_out
eddy_fcr$albedo <- met2$albedo

```

```{r Look at LW out and Net Radiation}
# Calculate vapor pressure deficit from RH and Air Temp using Met data
eddy_fcr$VPD <- ifelse(is.na(eddy_fcr$VPD), 
                       fCalcVPDfromRHandTair(rH = eddy_fcr$RH, Tair = eddy_fcr$air_temp_celsius)*100, 
                       eddy_fcr$VPD)

# Remove funky PAR_Tot values
eddy_fcr$par_tot <- ifelse(eddy_fcr$datetime >='2020-07-03' & eddy_fcr$datetime <= '2020-07-22', NA, eddy_fcr$par_tot)

# Replace wind_direction in EC data with Met data if missing
eddy_fcr$wind_dir <- ifelse(is.na(eddy_fcr$wind_dir), met4$WindDir, eddy_fcr$wind_dir)

# QA/QC'ing LW_out data
eddy_fcr$LW_out <- ifelse(eddy_fcr$LW_out <= 360, NA, eddy_fcr$LW_out)
eddy_fcr$LW_out <- ifelse(eddy_fcr$datetime >= '2020-06-22' & eddy_fcr$datetime <= '2020-07-13' & eddy_fcr$LW_out <= 420, NA, eddy_fcr$LW_out)

# Calculating Net Radiation
eddy_fcr$Rn <- eddy_fcr$SW_in - eddy_fcr$SW_out + eddy_fcr$LW_in - eddy_fcr$LW_out

plot(eddy_fcr$Rn, type = 'o')

plot(eddy_fcr$SW_in)

plot(eddy_fcr$VPD/1000)  # in kpa
```

```{r Filter out all the values (x_peak) that are out of the reservoir}

###############################################################################
# Filter out all the values (x_peak) that are out of the reservoir
eddy_fcr$footprint_flag <- ifelse(eddy_fcr$wind_dir >= 15 & eddy_fcr$wind_dir <= 90, 0, 
                                  ifelse(eddy_fcr$wind_dir < 15 & eddy_fcr$wind_dir > 327, 0,
                                         ifelse(eddy_fcr$wind_dir < 302 & eddy_fcr$wind_dir >= 250, 0, 0)))

# Remove flagged data
eddy_fcr_footprint <- eddy_fcr %>% filter(footprint_flag == 0)

# Visualize wind directions that were kept
eddy_fcr_footprint %>% ggplot(aes(wind_dir, x_peak_m)) + 
  geom_hline(yintercept = 40, col = 'goldenrod2', lwd = 2) +
  geom_hline(yintercept = 50, col = 'green', lwd = 1.4) +
  geom_hline(yintercept = 100, col = 'blue', lwd = 1.4) +
  geom_hline(yintercept = 120, col = 'gray2', lwd = 1.4) +
  geom_hline(yintercept = 150, col = 'red',lwd = 1.4) +
  geom_point() +
  scale_x_continuous(limits = c(0, 360),
                     breaks = seq(0, 360, 45)) +
  theme_bw() + 
  coord_polar()

# merge with timeseries
eddy_fcr_footprint_full <- left_join(ts2, eddy_fcr_footprint)

write.csv(eddy_fcr_footprint_full, "Eddy_fcr_footprint_full.csv")
```

```{r Filter by UStar and Gapfilling}
######################################################################
# FILTERING BY USTAR AND GAPFILLING
######################################################################

# Setting up a new process on REddyProc
eddy_fcr3 <- eddy_fcr_footprint_full %>% 
  select(DateTime = datetime, NEE = NEE.med, ch4_flux = ch4.med, VPD, 
         H = H_wm2, LE = LE_wm2, Tair = sonic_temp_celsius, rH = RH, Ustar = u_star_ms, u = wind_speed_ms, 
         pressure = air_pressure, L = L_m, z_d_L = MO_stability, sigma_v = v_var_ms, 
         precip, Rn, SW_in, SW_out, LW_out, LW_in, albedo, par_tot, wind_dir, 
         airP = air_pressure) %>% 
  mutate(VPD = VPD/100,
         z_d = z_d_L*L,
         ln_z_d = log(z_d),
         daytime = ifelse(SW_in >= 12, 1, 0)) %>% 
  rename(Rg = SW_in,
         PAR = par_tot)

########################################################################
# Count available data before gapfilling
eddy_fcr3 %>% select(DateTime, NEE, ch4_flux) %>% 
  summarise(co2_available = 100-sum(is.na(NEE))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux))/n()*100)
# 29% CO2 data; 23% CH4 data

# Total number of available time points
eddy_fcr3 %>% select(DateTime, NEE, ch4_flux) %>% 
  summarise(co2_available = n()-sum(is.na(NEE)),
            ch4_available = n()-sum(is.na(ch4_flux)))

# Counting data availability by month
eddy_fcr3 %>% group_by(year(DateTime), month(DateTime)) %>% 
  select(DateTime, NEE, ch4_flux) %>% 
  summarise(co2_available = 100-sum(is.na(NEE))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux))/n()*100)

# Visualizing data by wind direction/wind speed
# Save as: 800 x 800
windRose(mydata = eddy_fcr3, ws = "u", wd = "wind_dir", 
         width = 3, key.position = 'bottom', 
         offset = 3, paddle = FALSE, key.header = 'Wind speed (m/s)', 
         key.footer = ' ', dig.lab = 2, annotate = FALSE,
         angle.scale = 45, ws.int = 1, breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8),
         par.settings = list(fontsize=list(text=25)))
```

###Let's look at data availability for NEE

```{r Get Ustar distribution and filter by ustar}
###########################################################################
# get ustar distribution and filter by ustar
###########################################################################
# Gapfilling - using periods of similar met.
# Following Eddy Proc
Eproc <- sEddyProc$new('FCR', eddy_fcr3, c('NEE','Tair', 'VPD',
                                           'rH','H', 'LE', 'Ustar', 
                                           'ch4_flux', 'u', 'PAR', 
                                           'SW_out', 'Rg', 
                                           'Rn', 'LW_out', 'LW_in'))

# Look at available data for each year/flux
Eproc$sPlotFingerprintY('NEE',Year = '2020')
Eproc$sPlotFingerprintY('NEE',Year = '2021')
Eproc$sPlotFingerprintY('NEE',Year = '2022')
Eproc$sPlotFingerprintY('NEE',Year = '2023')
Eproc$sPlotFingerprintY('NEE',Year = '2024')
```

###Let's look at the Data Availability for CH4

```{r Ch4 data availability}
Eproc$sPlotFingerprintY('ch4_flux',Year = '2020')
Eproc$sPlotFingerprintY('ch4_flux',Year = '2021')
Eproc$sPlotFingerprintY('ch4_flux',Year = '2022')
Eproc$sPlotFingerprintY('ch4_flux',Year = '2023')
Eproc$sPlotFingerprintY('ch4_flux',Year = '2024')
```

```{r gapfill}
# gapfill air temperature, solar radiation, par, H and LE: include uncertainty calculations
Eproc$sMDSGapFill('Tair', V1 = 'Rg', V2 = 'VPD', FillAll = TRUE)
Eproc$sMDSGapFill('Rg',  V2 = 'VPD', V3 = 'Tair', FillAll = TRUE)
Eproc$sMDSGapFill('PAR', V1 = 'Rg', V2 = 'VPD', V3 = 'Tair', FillAll = TRUE)
Eproc$sMDSGapFill('Rn', V1 = 'Rg', V2 = 'VPD', V3 = 'Tair', FillAll = TRUE)
Eproc$sMDSGapFill('H', V1 = 'Rg', V2 = 'VPD', V3 = 'Tair', FillAll = TRUE)
Eproc$sMDSGapFill('LE', V1 = 'Rg', V2 = 'VPD', V3 = 'Tair', FillAll = TRUE)

```

```{r ustar distribution}
# Estimate ustar threshold distribution by bootstrapping the data
Eproc$sEstimateUstarScenarios(UstarColName = 'Ustar', NEEColName = 'NEE', RgColName= 'Rg',
                              nSample = 200L, probs = c(0.05, 0.5, 0.95))
```

```{r Bootstrap uncertainity beefed up}
# Beef up uncertainty following: https://github.com/bgctw/REddyProc/blob/master/vignettes/useCase.md
#Eproc$sEstimateUstarScenarios(UstarColName = 'Ustar', NEEColName = 'NEE', RgColName= 'Rg', 
#  nSample = 1000, probs = seq(0.025,0.975,length.out = 39))

Eproc$sGetEstimatedUstarThresholdDistribution()

Eproc$sGetUstarScenarios()
```

```{r More gap fill TAKES HOURSSS }
Eproc$sMDSGapFillUStarScens(fluxVar = 'NEE', FillAll = TRUE)
Eproc$sMDSGapFillUStarScens(fluxVar = 'ch4_flux', FillAll = TRUE)
```

```{r Try plotting daily sums}
# Try plotting daily sums
Eproc$sPlotDailySums('NEE_uStar_f','NEE_uStar_fsd')
Eproc$sPlotDailySums('ch4_flux_uStar_f')

Eproc$sPlotDiurnalCycle('NEE_uStar_f')
Eproc$sPlotDiurnalCycle('ch4_flux_uStar_f')

Eproc$sPlotHHFluxes('NEE_uStar_f')
Eproc$sPlotHHFluxes('ch4_flux_uStar_f')

# Export results from Eddy Proc
filled_fcr <- Eproc$sExportResults()
fcr_gf <- cbind(eddy_fcr3, filled_fcr)
```

```{r Quick plots as gut check}
### Quick plots as a gut-check/initial cut

fcr_gf %>% ggplot() + 
  geom_point(aes(DateTime, ch4_flux_uStar_orig), alpha = 0.3) +
  geom_line(aes(DateTime, ch4_flux_uStar_f - ch4_flux_uStar_fsd), alpha = 0.3)+
  geom_line(aes(DateTime, ch4_flux_uStar_fsd + ch4_flux_uStar_fsd), alpha = 0.3)+
  geom_line(aes(DateTime, ch4_flux_uStar_f), col = 'red', alpha = 0.5) +
  theme_bw() +
  xlab("") + ylab(expression(~CH[4]~flux~(mu~mol~m^-2~s^-1)))

# Plot as points + daily average
fcr_gf_mean <- fcr_gf %>% 
  mutate(DateTime = format(as.POSIXct(DateTime, "%Y-%m-%d"),"%Y-%m-%d")) %>% 
  mutate(DateTime = as.POSIXct(DateTime, "%Y-%m-%d")) %>% 
  group_by(DateTime) %>% 
  summarise_all(mean,na.rm=TRUE)

fcr_gf %>% ggplot() +
  #geom_point(aes(DateTime, NEE),alpha=0.1) +
  geom_line(aes(DateTime, NEE_uStar_f), col='red', alpha = 0.4) +
  geom_line(aes(DateTime, NEE_U50_f), col = 'blue', alpha = 0.4)+
  theme_bw() +
  xlab("") + ylab(expression(~CO[2]~flux~(mu~mol~m^-2~s^-1)))

ggplot()+
  geom_vline(xintercept = as.POSIXct("2020-11-01"),linetype="dotted")+ #Turnover FCR; operationally defined
  geom_point(fcr_gf, mapping = aes(DateTime, NEE_uStar_orig*60*60*24*44.01/1e6),alpha = 0.1)+
  geom_hline(yintercept = 0, linetype="dashed")+
  geom_line(fcr_gf_mean, mapping = aes(DateTime, NEE_uStar_f*60*60*24*44.01/1e6),color="#E63946",size = 1)+
  theme_classic(base_size = 15)+
  xlab("") + ylab(expression(~CO[2]~flux~(g~m^-2~d^-1)))

ggplot()+
  geom_vline(xintercept = as.POSIXct("2020-11-01"),linetype="dotted")+ #Turnover FCR; operationally defined
  geom_point(fcr_gf, mapping = aes(DateTime, ch4_flux_uStar_orig*60*60*24*16.04/1e6),alpha = 0.1)+
  geom_hline(yintercept = 0, linetype="dashed")+
  geom_line(fcr_gf_mean, mapping = aes(DateTime, ch4_flux_uStar_f*60*60*24*16.04/1e6),color="#E63946",size = 1)+
  theme_classic(base_size = 15)+
  xlab("") + ylab(expression(~CH[4]~flux~(g~m^-2~d^-1)))
```

```{r Save data file}

# Save the exported data
write_csv(fcr_gf, paste0(Sys.Date(),"_EC_processed_withBDScript.csv"))

```

```{r EDDyflux plots }
# Make plots here while the other Markdown is processing



fcr_gf%>%
  ggplot(.,aes(x=DateTime))+
  geom_point(aes(y=NEE_uStar_f), color="black")+
  geom_point(aes(y=NEE), color="red")+
  xlab("Date") + ylab("umolL") +
  ggtitle("FCR EddyFlux Gap Filled CO2")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(text = element_text(size=20))

ggsave("FCR_CO2 gap filled.jpg", width=11, height=7, units="in")

fcr_gf%>%
  ggplot(.,aes(x=DateTime))+
  geom_point(aes(y=ch4_flux_uStar_f), color="black")+
  geom_point(aes(y=ch4_flux), color="red")+
  xlab("Date") + ylab("umolL") +
  ggtitle("FCR EddyFlux CH4")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(text = element_text(size=20))

ggsave("FCR_Ch4 gap filled.jpg", width=11, height=7, units="in")

fcr_gf%>%
  mutate(Date=as.Date(DateTime))%>%
  group_by(Date)%>%
  summarise(NEE_mean = mean(NEE, na.rm=T))%>%
  ungroup()%>%
  mutate(DOY=yday(Date))%>%
  mutate(Year=year(Date))%>%
  ggplot(., aes(x=DOY, y=NEE_mean, color=as.factor(Year)))+
  geom_point()+
  xlab("DOY") + ylab("umolL") +
  ggtitle("FCR Daily Average Co2 Flux")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(text = element_text(size=20))

ggsave("FCR_CO2_Daily_Average.jpg", width=11, height=7, units="in")

fcr_gf%>%
  mutate(Date=as.Date(DateTime))%>%
  group_by(Date)%>%
  summarise(ch4_flux_mean = mean(ch4_flux, na.rm=T))%>%
  ungroup()%>%
  mutate(DOY=yday(Date))%>%
  mutate(Year=year(Date))%>%
  ggplot(., aes(x=DOY, y=ch4_flux_mean, color=as.factor(Year)))+
  geom_point()+
  xlab("DOY") + ylab("umolL") +
  ggtitle("FCR Daily Average CH4 Flux")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))+
  theme(text = element_text(size=20))

ggsave("FCR_CH4_Daily_Average.jpg", width=11, height=7, units="in")
```
